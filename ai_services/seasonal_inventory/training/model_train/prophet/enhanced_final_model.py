"""
Enhanced Final Prophet Model with Advanced Spike Handling
Integrates holiday regressors + spike pattern handling for production use
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from prophet import Prophet
from prophet.utilities import regressor_coefficients
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import IsolationForest
import warnings
from datetime import datetime, timedelta
import holidays

warnings.filterwarnings('ignore')

def create_comprehensive_holiday_calendar():
    """Create comprehensive holiday calendar with seasonal patterns"""
    
    # Key holidays identified from demand analysis
    major_holidays = pd.DataFrame([
        # Black Friday & Cyber Monday
        {'holiday': 'black_friday', 'ds': '2022-11-25', 'lower_window': -1, 'upper_window': 1},
        {'holiday': 'black_friday', 'ds': '2023-11-24', 'lower_window': -1, 'upper_window': 1},
        {'holiday': 'black_friday', 'ds': '2024-11-29', 'lower_window': -1, 'upper_window': 1},
        
        {'holiday': 'cyber_monday', 'ds': '2022-11-28', 'lower_window': 0, 'upper_window': 0},
        {'holiday': 'cyber_monday', 'ds': '2023-11-27', 'lower_window': 0, 'upper_window': 0},
        {'holiday': 'cyber_monday', 'ds': '2024-12-02', 'lower_window': 0, 'upper_window': 0},
        
        # Christmas season
        {'holiday': 'christmas_season', 'ds': '2022-12-24', 'lower_window': -3, 'upper_window': 2},
        {'holiday': 'christmas_season', 'ds': '2023-12-24', 'lower_window': -3, 'upper_window': 2},
        {'holiday': 'christmas_season', 'ds': '2024-12-24', 'lower_window': -3, 'upper_window': 2},
        
        # New Year's Eve
        {'holiday': 'new_year_eve', 'ds': '2022-12-31', 'lower_window': 0, 'upper_window': 0},
        {'holiday': 'new_year_eve', 'ds': '2023-12-31', 'lower_window': 0, 'upper_window': 0},
        {'holiday': 'new_year_eve', 'ds': '2024-12-31', 'lower_window': 0, 'upper_window': 0},
        
        # Valentine's Day
        {'holiday': 'valentine_day', 'ds': '2022-02-14', 'lower_window': -1, 'upper_window': 1},
        {'holiday': 'valentine_day', 'ds': '2023-02-14', 'lower_window': -1, 'upper_window': 1},
        {'holiday': 'valentine_day', 'ds': '2024-02-14', 'lower_window': -1, 'upper_window': 1},
        
        # Summer surge periods (identified from spike analysis)
        {'holiday': 'summer_peak', 'ds': '2022-07-16', 'lower_window': -2, 'upper_window': 2},
        {'holiday': 'summer_peak', 'ds': '2023-07-15', 'lower_window': -2, 'upper_window': 2},
        {'holiday': 'summer_peak', 'ds': '2024-07-15', 'lower_window': -2, 'upper_window': 2},
    ])
    
    major_holidays['ds'] = pd.to_datetime(major_holidays['ds'])
    return major_holidays

def create_enhanced_regressors(data):
    """Create enhanced regressors for spike handling"""
    
    enhanced_data = data.copy()
    
    # 1. Weekend intensity (graduated scale)
    enhanced_data['weekend_intensity'] = 0
    enhanced_data.loc[enhanced_data['ds'].dt.dayofweek == 4, 'weekend_intensity'] = 0.5  # Thursday
    enhanced_data.loc[enhanced_data['ds'].dt.dayofweek == 5, 'weekend_intensity'] = 1.0  # Friday
    enhanced_data.loc[enhanced_data['ds'].dt.dayofweek == 6, 'weekend_intensity'] = 2.0  # Saturday (peak)
    enhanced_data.loc[enhanced_data['ds'].dt.dayofweek == 0, 'weekend_intensity'] = 1.5  # Sunday
    
    # 2. Month-end effect (last 3 days of month)
    enhanced_data['month_end_effect'] = 0
    for idx, row in enhanced_data.iterrows():
        days_to_end = (row['ds'] + pd.offsets.MonthEnd(0) - row['ds']).days
        if days_to_end <= 2:
            enhanced_data.loc[idx, 'month_end_effect'] = 3 - days_to_end  # 3, 2, 1 for last 3 days
    
    # 3. Payday effect (1st and 15th of month)
    enhanced_data['payday_effect'] = 0
    day_of_month = enhanced_data['ds'].dt.day
    enhanced_data.loc[day_of_month == 1, 'payday_effect'] = 2.0  # 1st (stronger effect)
    enhanced_data.loc[day_of_month == 15, 'payday_effect'] = 1.5  # 15th
    enhanced_data.loc[day_of_month == 2, 'payday_effect'] = 1.0   # 2nd (carryover)
    enhanced_data.loc[day_of_month == 16, 'payday_effect'] = 0.8  # 16th (carryover)
    
    # 4. Summer surge (June-August with July peak)
    enhanced_data['summer_surge'] = 0
    month = enhanced_data['ds'].dt.month
    enhanced_data.loc[month == 6, 'summer_surge'] = 1.0  # June
    enhanced_data.loc[month == 7, 'summer_surge'] = 2.0  # July (peak)
    enhanced_data.loc[month == 8, 'summer_surge'] = 1.0  # August
    
    # 5. Pre-holiday shopping surge (3 days before major holidays)
    enhanced_data['pre_holiday_surge'] = 0
    
    # Christmas pre-shopping
    christmas_dates = ['2022-12-25', '2023-12-25', '2024-12-25']
    for xmas in christmas_dates:
        xmas_date = pd.to_datetime(xmas)
        for days_before in [1, 2, 3]:
            surge_date = xmas_date - timedelta(days=days_before)
            mask = enhanced_data['ds'] == surge_date
            enhanced_data.loc[mask, 'pre_holiday_surge'] = 4 - days_before  # 3, 2, 1
    
    return enhanced_data

def handle_outliers(data, method='cap', threshold=3):
    """Handle extreme outliers in the data"""
    
    processed_data = data.copy()
    
    if method == 'cap':
        # Cap outliers at threshold standard deviations
        mean_demand = processed_data['y'].mean()
        std_demand = processed_data['y'].std()
        upper_cap = mean_demand + threshold * std_demand
        lower_cap = max(0, mean_demand - threshold * std_demand)
        
        original_outliers = ((processed_data['y'] > upper_cap) | (processed_data['y'] < lower_cap)).sum()
        processed_data['y'] = np.clip(processed_data['y'], lower_cap, upper_cap)
        
        print(f"   ðŸ“Š Outlier handling: {original_outliers} values capped (threshold: {threshold}Ïƒ)")
        
    elif method == 'log_transform':
        # Log transformation to reduce impact of extreme values
        processed_data['y_original'] = processed_data['y']
        processed_data['y'] = np.log1p(processed_data['y'])  # log(1 + x) to handle zeros
        print(f"   ðŸ“Š Applied log transformation to reduce outlier impact")
        
    return processed_data

def prepare_enhanced_data():
    """Load and prepare data with all enhancements"""
    print("Loading and preparing enhanced data with spike handling...")
    
    df = pd.read_csv('daily_demand_by_product_modern.csv')
    df['ds'] = pd.to_datetime(df['ds'])
    
    # Get category-level data
    category_data = df.groupby(['category', 'ds'])['y'].sum().reset_index()
    
    # Create holiday calendar
    holidays_df = create_comprehensive_holiday_calendar()
    
    # Add enhanced regressors
    category_data = create_enhanced_regressors(category_data)
    
    categories = df['category'].unique()
    print(f"Categories found: {list(categories)}")
    print(f"Date range: {df['ds'].min()} to {df['ds'].max()}")
    print(f"Total data points: {len(df):,}")
    print(f"Holiday events: {len(holidays_df)} defined")
    print(f"Enhanced regressors: weekend_intensity, month_end_effect, payday_effect, summer_surge, pre_holiday_surge")
    
    return category_data, categories, holidays_df

def optimize_enhanced_parameters(train_data, test_data, category_name, holidays_df):
    """Optimize parameters with enhanced spike handling"""
    print(f"\nOptimizing enhanced parameters for {category_name}...")
    
    actual = test_data['y'].values
    
    # Enhanced parameter configurations
    param_configs = [
        {
            'name': 'Enhanced Basic',
            'params': {'holidays': holidays_df},
            'regressors': ['weekend_intensity']
        },
        {
            'name': 'Enhanced Weekend + Month-end',
            'params': {'holidays': holidays_df, 'changepoint_prior_scale': 0.1},
            'regressors': ['weekend_intensity', 'month_end_effect']
        },
        {
            'name': 'Enhanced Full Spike Handling',
            'params': {'holidays': holidays_df, 'changepoint_prior_scale': 0.1},
            'regressors': ['weekend_intensity', 'month_end_effect', 'payday_effect']
        },
        {
            'name': 'Enhanced with Summer Patterns',
            'params': {'holidays': holidays_df, 'changepoint_prior_scale': 0.1},
            'regressors': ['weekend_intensity', 'month_end_effect', 'payday_effect', 'summer_surge']
        },
        {
            'name': 'Enhanced Complete',
            'params': {'holidays': holidays_df, 'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 5},
            'regressors': ['weekend_intensity', 'month_end_effect', 'payday_effect', 'summer_surge', 'pre_holiday_surge']
        },
        {
            'name': 'Enhanced Multiplicative',
            'params': {'holidays': holidays_df, 'seasonality_mode': 'multiplicative'},
            'regressors': ['weekend_intensity', 'month_end_effect', 'payday_effect']
        }
    ]
    
    results = {}
    best_rmse = float('inf')
    best_config = None
    
    for config in param_configs:
        try:
            model = Prophet(**config['params'])
            
            # Add regressors
            for regressor in config['regressors']:
                model.add_regressor(regressor, prior_scale=10, standardize=True)
            
            # Prepare training data
            train_cols = ['ds', 'y'] + config['regressors']
            model.fit(train_data[train_cols])
            
            # Prepare test data and predict
            test_cols = ['ds'] + config['regressors']
            forecast = model.predict(test_data[test_cols])
            
            pred = forecast['yhat'].values
            rmse = np.sqrt(mean_squared_error(actual, pred))
            mae = mean_absolute_error(actual, pred)
            r2 = r2_score(actual, pred)
            
            results[config['name']] = {
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'params': config['params'],
                'regressors': config['regressors'],
                'model': model
            }
            
            if rmse < best_rmse:
                best_rmse = rmse
                best_config = config
                
        except Exception as e:
            print(f"  Error with {config['name']}: {str(e)}")
    
    # Print results
    print(f"  Enhanced Results for {category_name}:")
    for name, metrics in results.items():
        print(f"    {name:30s}: RMSE={metrics['rmse']:6.1f}, MAE={metrics['mae']:6.1f}, RÂ²={metrics['r2']:5.3f}")
    
    print(f"  ðŸ† Best Enhanced: {best_config['name']} (RMSE: {best_rmse:.1f})")
    
    return best_config, results

def train_enhanced_model(data, category, best_params, best_regressors, forecast_days=30):
    """Train final enhanced model"""
    
    # Apply outlier handling
    processed_data = handle_outliers(data, method='cap', threshold=3)
    
    # Train on all available data
    model = Prophet(**best_params)
    
    # Add regressors
    for regressor in best_regressors:
        model.add_regressor(regressor, prior_scale=10, standardize=True)
    
    # Prepare training data
    train_cols = ['ds', 'y'] + best_regressors
    model.fit(processed_data[train_cols])
    
    # Generate future dataframe with regressors
    future = model.make_future_dataframe(periods=forecast_days)
    
    # Add regressor values for future dates
    future = create_enhanced_regressors(future)
    
    # Generate forecast
    future_cols = ['ds'] + best_regressors
    forecast = model.predict(future[future_cols])
    
    return model, forecast

def main_enhanced():
    """Main execution function with enhanced spike handling"""
    
    print("="*80)
    print("ENHANCED PROPHET MODEL - ADVANCED SPIKE HANDLING")
    print("="*80)
    
    # Load enhanced data
    category_data, categories, holidays_df = prepare_enhanced_data()
    
    # Results storage
    all_results = {}
    
    # Process each category
    for category in categories:
        print(f"\n{'='*60}")
        print(f"PROCESSING CATEGORY: {category.upper()} (ENHANCED)")
        print(f"{'='*60}")
        
        # Get category data
        cat_data = category_data[category_data['category'] == category].copy()
        cat_data = cat_data.sort_values('ds').reset_index(drop=True)
        
        print(f"Data points: {len(cat_data)}")
        print(f"Date range: {cat_data['ds'].min()} to {cat_data['ds'].max()}")
        print(f"Demand range: {cat_data['y'].min():.0f} to {cat_data['y'].max():.0f}")
        
        # Split data (80/20)
        split_idx = int(len(cat_data) * 0.8)
        train_data = cat_data[:split_idx].copy()
        test_data = cat_data[split_idx:].copy()
        split_date = test_data['ds'].iloc[0]
        
        print(f"Train period: {train_data['ds'].min()} to {train_data['ds'].max()}")
        print(f"Test period: {test_data['ds'].min()} to {test_data['ds'].max()}")
        
        # Optimize enhanced parameters
        best_config, optimization_results = optimize_enhanced_parameters(train_data, test_data, category, holidays_df)
        
        # Train enhanced model
        print(f"\nTraining enhanced model for {category}...")
        enhanced_model, forecast = train_enhanced_model(
            cat_data, category, 
            best_config['params'], 
            best_config['regressors']
        )
        
        # Store results
        all_results[category] = {
            'best_config': best_config,
            'optimization_results': optimization_results,
            'model': enhanced_model,
            'forecast': forecast,
            'data': cat_data
        }
        
        # Calculate enhanced metrics
        test_cols = ['ds'] + best_config['regressors']
        test_forecast = enhanced_model.predict(test_data[test_cols])
        
        test_rmse = np.sqrt(mean_squared_error(test_data['y'], test_forecast['yhat']))
        test_mae = mean_absolute_error(test_data['y'], test_forecast['yhat'])
        test_r2 = r2_score(test_data['y'], test_forecast['yhat'])
        
        print(f"Enhanced test metrics:")
        print(f"  RMSE: {test_rmse:.1f}")
        print(f"  MAE: {test_mae:.1f}")
        print(f"  RÂ²: {test_r2:.3f}")
        print(f"  Regressors used: {', '.join(best_config['regressors'])}")
    
    # Enhanced summary
    print(f"\n{'='*80}")
    print("ENHANCED MODEL SUMMARY")
    print(f"{'='*80}")
    
    total_rmse_improvement = 0
    baseline_rmse = {
        'books_media': 671.8, 'clothing': 3651.3, 'electronics': 2848.6,
        'health_beauty': 1754.0, 'home_garden': 1257.7, 'sports_outdoors': 1093.3
    }
    
    print("Enhanced configurations by category:")
    for category, results in all_results.items():
        best = results['best_config']
        current_rmse = results['optimization_results'][best['name']]['rmse']
        improvement = baseline_rmse.get(category, current_rmse) - current_rmse
        total_rmse_improvement += improvement
        
        print(f"\n{category:15s}: {best['name']}")
        print(f"  {'':15s}  RMSE: {current_rmse:.1f} (improved by {improvement:.1f})")
        print(f"  {'':15s}  Regressors: {', '.join(best['regressors'])}")
    
    print(f"\nðŸŽ¯ Enhanced Model Benefits:")
    print(f"   â€¢ Total RMSE improvement: {total_rmse_improvement:.1f}")
    print(f"   â€¢ Spike pattern handling: Weekend, month-end, payday effects")
    print(f"   â€¢ Outlier management: Statistical capping applied")
    print(f"   â€¢ Seasonal enhancements: Summer surge detection")
    print(f"   â€¢ Advanced holiday calendar: Pre-shopping surge detection")
    
    return all_results

if __name__ == "__main__":
    results = main_enhanced()
    
    print(f"\n{'='*80}")
    print("ENHANCED EXECUTION COMPLETE!")
    print(f"{'='*80}")
    print("âœ… All categories trained with enhanced spike handling")
    print("âœ… Outlier management implemented")
    print("âœ… Advanced pattern detection active")
    print("âœ… Production-ready with comprehensive spike handling")
